# #!/usr/bin/env bash
# # ============================================================
# # ğŸ§  AIAI End-to-End Pipeline (Steps 1~18)
# # ------------------------------------------------------------
# # ì „ì²´ ê°œìš”:
# #  - Steps 1~10: ë¹„ë””ì˜¤ ë°ì´í„° ì „ì²˜ë¦¬ ë° feature ìƒì„±
# #  - Steps 11~15: CASE ëª¨ë¸ í•™ìŠµ ë° ê²°ê³¼ ì •ë¦¬
# #  - Steps 16~18: ì¸êµ¬í†µê³„ ì„¤ë¬¸ ë³‘í•© + ìµœì¢… ML í•™ìŠµ
# # ------------------------------------------------------------
# # ì‹¤í–‰ ìœ„ì¹˜ : í”„ë¡œì íŠ¸ ë£¨íŠ¸ (ì˜ˆ: /ASD-Project_DHLAB)
# # ë¡œê·¸ íŒŒì¼ : logs/pipeline_YYYYMMDD_HHMMSS.log
# # ============================================================

# set -Eeuo pipefail

# # -----------------------------
# # âœ… 0) í™˜ê²½ ì„¤ì •
# # -----------------------------
# cd "$(dirname "$0")"
# ROOT="$(pwd)"
# LOG_DIR="$ROOT/logs"
# mkdir -p "$LOG_DIR"
# LOG_FILE="$LOG_DIR/pipeline_$(date +%Y%m%d_%H%M%S).log"
# exec > >(tee -a "$LOG_FILE") 2>&1

# echo "ğŸ“ WORKDIR: $ROOT"
# echo "ğŸ—’ï¸ LOG    : $LOG_FILE"

# step() {
#   echo ""
#   echo "========================================"
#   echo "[$(date '+%F %T')] STEP $1 :: $2"
#   echo "========================================"
# }

# # ============================================================
# # ğŸ§© [1~10ë‹¨ê³„] ë¹„ë””ì˜¤ â†’ í”„ë ˆì„ â†’ Feature ì¶”ì¶œ íŒŒì´í”„ë¼ì¸
# # ============================================================

# # 1) ëª¨ë“  ë¹„ë””ì˜¤ ê²½ë¡œë¥¼ ìŠ¤ìº”í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ CSV ìƒì„±
# #    ì¶œë ¥: data/lists/unmatching_video_list.csv
# step 1 "Extract video list"
# python3 data_preprocess/1_extract_video_list.py

# # 2) ê° ë¹„ë””ì˜¤(.mp4)ë¥¼ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë¶„í•´ (1ì´ˆ ê°„ê²©)
# #    ì¶œë ¥: data/preprocessed/unmatching_videos_frames/
# step 2 "Extract frames for each video"
# python3 data_preprocess/2_extract_frames_for_list.py

# # 3) í”„ë ˆì„ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ instance list (.txt) ì‘ì„±
# #    ê° ì˜ìƒì˜ ê²½ë¡œ ë° label ì •ë³´ë¥¼ í¬í•¨
# #    ì¶œë ¥: data/lists/unmatched_instance_list.txt
# step 3 "Build unmatched instance list"
# python3 data_preprocess/3_get_instance_list.py

# # 4) SlowFast (mmaction2)ë¡œ ì˜ìƒ feature(.pkl) ì¶”ì¶œ
# #    CONFIG / CKPTëŠ” SlowFast pretrained ì„¤ì • ì‚¬ìš©
# #    ì¶œë ¥: ê° í”„ë ˆì„ í´ë” í•˜ìœ„ì— .pkl íŒŒì¼ ìƒì„±
# CONFIG="model/mmaction2/configs/recognition/slowfast/slowfast_r50_8xb8-4x16x1-256e_kinetics400-rgb.py"
# CKPT="model/mmaction2/ckpts/slowfast_r50_8xb8-8x8x1-256e_kinetics400-rgb_20220818-1cb6dfc8.pth"
# FEAT_OUT="data/preprocessed/unmatching_videos_frames"
# step 4 "Extract SlowFast clip features"
# python3 model/mmaction2/tools/misc/clip_feature_extraction.py "$CONFIG" "$CKPT" "$FEAT_OUT"

# # 5) í”„ë ˆì„ í´ë”ì—ì„œ ìƒì„±ëœ .pkl íŒŒì¼ë§Œ êµ¬ì¡° ìœ ì§€í•˜ë©° ì´ë™
# #    ì…ë ¥: data/preprocessed/unmatching_videos_frames
# #    ì¶œë ¥: data/preprocessed/unmatching_features
# step 5 "Move .pkl features to structured dir"
# bash data_preprocess/5_move_pkl.sh

# # 6) ê° instanceë³„ .pkl featureë¥¼ ë³‘í•©í•˜ì—¬ í•˜ë‚˜ì˜ .npyë¡œ ì €ì¥
# #    ì…ë ¥: data/preprocessed/unmatching_features
# #    ì¶œë ¥: data/preprocessed/unmatching_npy
# step 6 "Merge .pkl â†’ .npy files"
# python3 data_preprocess/6_create_npy_files.py \
#   --root_dir ./data/preprocessed/unmatching_features \
#   --target_dir ./data/preprocessed/unmatching_npy

# # 7) Task / Month ê¸°ì¤€ìœ¼ë¡œ NPYë¥¼ ë¶„ë¥˜í•˜ì—¬ ë³µì‚¬
# #    ì˜ˆ: task_AF, task_D, task_G, ...
# #    ì¶œë ¥: data/splits/task_*/cell_month_*/input_npy/
# step 7 "Split NPY files by Task & Month"
# python3 data_preprocess/7_select_month_task_npy.py

# # 8) ê° Task/Monthë³„ë¡œ ì •ìƒêµ° ë¼ë²¨ CSV ìƒì„±
# #    ì…ë ¥: normal_patients.csv
# #    ì¶œë ¥: input_label.csv (0=Normal, 1=Others)
# step 8 "Create label CSVs for each Task/Month"
# bash data_preprocess/8_1_create_true_label_csv.sh

# # 9) Foldë³„ CSVë¥¼ ê¸°ë°˜ìœ¼ë¡œ split txt/json/statistics ìƒì„±
# #    ì¶œë ¥: gt_foldX.json, split_train/valid/test_fold_X.txt
# step 9 "Generate split txt/json for 5-fold structure"
# python3 data_preprocess/9_split_csv_by_csv.py

# # 10) í•™ìŠµìš© feature êµ¬ì¡°ë¡œ ì •ë¦¬ (ë³µì‚¬)
# #     ì¶œë ¥: input_data_no_matching/features/rgb/
# step 10 "Copy feature npy files to training structure"
# bash data_preprocess/10_mv_features_for_train.sh

# echo ""
# echo "âœ… Preprocessing completed (Steps 1~10)."

# # ============================================================
# # ğŸ§© [11~15ë‹¨ê³„] CASE ëª¨ë¸ í•™ìŠµ ë° ê²°ê³¼ ìš”ì•½
# # ============================================================

# # 11) CASE ëª¨ë¸ í•™ìŠµ (matching dataset)
# step 11 "CASE model training"
# bash model/CASE/11_run_2025_aiai_AF_group_match_E_cell_all_matching.sh

# # 12) CASE ëª¨ë¸ inference-only ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ì…‹)
# step 12 "CASE inference_only"
# bash model/CASE/12_run_2025_aiai_AF_group_match_E_cell_all_test_matching.sh

# 13) outputs/ ì•„ë˜ì—ì„œ CSV íŒŒì¼ë§Œ ì¶”ì¶œ (í´ë” êµ¬ì¡° ìœ ì§€)
#     ì¶œë ¥: outputs_csv/
step 13 "Collect only result CSVs from outputs"
python3 model/CASE/13_copy_only_results_csv.py \
  --src ./outputs \
  --dst ./outputs_csv

# 14) foldë³„ë¡œ train/valid/test split ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ë³‘í•©
#     ì…ë ¥: outputs_csv + data/folds/matching_fold
#     ì¶œë ¥: outputs_csv_summaries/
step 14 "Summarize results by fold/split"
python3 data_preprocess/14_sum_results_csv.py \
  --results_base_dir ./outputs_csv \
  --folds_base_dir ./data/folds/matching_fold \
  --output_dir ./outputs_csv_summaries \
  --num_folds 5 \
  --prob_col prob_class_0

# 15) ì •ìƒêµ° ë¦¬ìŠ¤íŠ¸(normal_patients.csv)ë¥¼ ì´ìš©í•´
#     group ì»¬ëŸ¼ ì¶”ê°€ (0=Normal, 1=Others)
step 15 "Add group column (Normal/Others)"
python3 data_preprocess/15_matching_group.py \
  --csv_folder ./outputs_csv_summaries \
  --normal_list ./data/lists/normal_patients.csv \
  --overwrite

echo "ğŸ‰ CASE results aggregation completed (Steps 11~15)."

# ============================================================
# ğŸ§© [16~18ë‹¨ê³„] ì„¤ë¬¸ ë³‘í•© ë° ìµœì¢… ML í•™ìŠµ
# ============================================================

# 16) Demography ì„¤ë¬¸ ì „ì²˜ë¦¬ (P1~P5)
#     ì…ë ¥: ./data/Demography_all.xlsx
#     ì¶œë ¥: ./data/preprocessed/tabular/Demo_processed.csv
step 16 "Preprocess Demography survey (P1~P5)"
python3 data_preprocess/16_preprocessing_demo.py

# 17) ì„¤ë¬¸ + ëª¨ë¸ ìš”ì•½ ê²°ê³¼ ë³‘í•© (LEFT JOIN on patient_id)
#     ì…ë ¥: outputs_csv_summaries + Demo_processed.csv
#     ì¶œë ¥: data/final_data/
step 17 "Merge Demography with model results"
python3 data_preprocess/17_merge_demo_with_results.py \
  --results_dir ./outputs_csv_summaries \
  --demo_csv ./data/preprocessed/tabular/Demo_processed.csv \
  --output_dir ./data/final_data \
  --key patient_id

# 18) ìµœì¢… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ (GridSearch/RFE/F1/AUC ì¡°í•©)
#     ì‹¤í–‰: model/run.sh
#     ì¶œë ¥: ./model_results_matching/
step 18 "Run final matching ML model (RFE/Grid/Metric/Impute sweep)"
bash model/run.sh

echo ""
echo "ğŸ¯ âœ… Pipeline fully completed (Steps 1â€“18)"
echo "ğŸ“¦ Final merged data : ./data/final_data/"
echo "ğŸ“Š Model results     : ./model_results_matching/"
echo "ğŸ§© Logs              : $LOG_FILE"